{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import itertools\n",
    "from gym import spaces\n",
    "import itertools\n",
    "\n",
    "class StickGameEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(StickGameEnv, self).__init__()\n",
    "        self.all_combinations = generate_all_combinations()\n",
    "        self.action_space = spaces.Discrete(len(self.all_combinations))\n",
    "        self.observation_space = spaces.MultiBinary(12)\n",
    "        self.state = None\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = np.ones(12, dtype=int)\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        action = int(action)\n",
    "        combination = self.all_combinations[action]\n",
    "        if not self._is_valid_action(combination):\n",
    "            return self.state, 0, True, {}  # Invalid action, end the game\n",
    "\n",
    "        for stick in combination:\n",
    "            self.state[stick] = 0\n",
    "\n",
    "        done = np.all(self.state == 0)\n",
    "        reward = 1 if done else 0\n",
    "\n",
    "        return self.state, reward, done, {}\n",
    "\n",
    "    def _is_valid_action(self, combination):\n",
    "        return all(self.state[stick] == 1 for stick in combination)\n",
    "\n",
    "    def valid_actions(self):\n",
    "        dice_roll = np.random.randint(2, 13)\n",
    "        sticks = [i + 1 for i, present in enumerate(self.state) if present == 1]\n",
    "\n",
    "        valid = []\n",
    "        for L in range(1, len(sticks) + 1):\n",
    "            for subset in itertools.combinations(sticks, L):\n",
    "                if sum(subset) == dice_roll:\n",
    "                    subset_action = np.zeros(12, dtype=int)\n",
    "                    for stick in subset:\n",
    "                        subset_action[stick - 1] = 1\n",
    "                    if np.all(subset_action <= self.state):\n",
    "                        valid.append(subset_action)\n",
    "        return valid\n",
    "\n",
    "def generate_all_combinations():\n",
    "    all_combinations = {}\n",
    "    action_id = 0\n",
    "\n",
    "    for dice_roll in range(2, 13):\n",
    "        for num_sticks in range(1, dice_roll + 1):\n",
    "            for combination in itertools.combinations(range(12), num_sticks):\n",
    "                if sum(combination) + len(combination) == dice_roll:\n",
    "                    all_combinations[action_id] = combination\n",
    "                    action_id += 1\n",
    "\n",
    "    return all_combinations\n",
    "\n",
    "all_combinations = generate_all_combinations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# Create the environment\n",
    "env = make_vec_env(lambda: StickGameEnv(), n_envs=1)\n",
    "\n",
    "# Initialize the DQN model\n",
    "model = DQN(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=1e6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, num_episodes=100):\n",
    "    env = StickGameEnv()\n",
    "    win_count = 0\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action, _states = model.predict(obs, deterministic=True)\n",
    "            obs, rewards, done, info = env.step(action)\n",
    "            if done and rewards == 1:\n",
    "                win_count += 1\n",
    "\n",
    "    win_rate = win_count / num_episodes\n",
    "    return win_rate\n",
    "\n",
    "# Evaluate the trained model\n",
    "win_rate = evaluate_model(model, num_episodes=10000)\n",
    "print(\"Win Rate:\", win_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import itertools\n",
    "from gymnasium import spaces\n",
    "\n",
    "class StickGameEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(StickGameEnv, self).__init__()\n",
    "        self.all_combinations = generate_all_combinations()\n",
    "        self.action_space = spaces.Discrete(len(self.all_combinations))\n",
    "\n",
    "        # Define observation space with 12 elements for sticks and 1 element for the dice roll\n",
    "        # Sticks can be 0 or 1, dice roll can be between 2 and 12\n",
    "        self.observation_space = spaces.Box(low=0, high=12, shape=(13,), dtype=int)\n",
    "\n",
    "        self.state = None\n",
    "        self.dice_roll = None\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        self.state = np.ones(12, dtype=int)  # Reset stick state\n",
    "        self.dice_roll = self._roll_dice()   # Initial dice roll\n",
    "        initial_observation = np.append(self.state, self.dice_roll)\n",
    "        return initial_observation, {}  # Return observation and empty info dictionary\n",
    "\n",
    "    def step(self, action):\n",
    "        action = int(action)\n",
    "        combination = self.all_combinations[action]\n",
    "\n",
    "        if not self._is_valid_action(combination):\n",
    "            return np.append(self.state, self.dice_roll), -1, False, False, {}  # Penalize for invalid action\n",
    "\n",
    "        for stick in combination:\n",
    "            self.state[stick - 1] = 0\n",
    "\n",
    "        terminated = bool(np.all(self.state == 0))\n",
    "        reward = 1 if terminated else 0\n",
    "\n",
    "        # Roll the dice for the next state\n",
    "        self.dice_roll = self._roll_dice()\n",
    "        truncated = False  # This can be modified as per your game logic if there's a truncation condition\n",
    "        return np.append(self.state, self.dice_roll), reward, terminated, truncated, {}\n",
    "\n",
    "    def _roll_dice(self):\n",
    "        return np.random.randint(1, 7) + np.random.randint(1, 7)  # Two dice roll\n",
    "\n",
    "    def _is_valid_action(self, combination):\n",
    "        return all(self.state[stick - 1] == 1 for stick in combination)\n",
    "\n",
    "    def valid_actions(self):\n",
    "        dice_roll = np.random.randint(2, 13)\n",
    "        sticks = [i + 1 for i, present in enumerate(self.state) if present == 1]\n",
    "\n",
    "        valid = []\n",
    "        for L in range(1, len(sticks) + 1):\n",
    "            for subset in itertools.combinations(sticks, L):\n",
    "                if sum(subset) == dice_roll:\n",
    "                    subset_action = np.zeros(12, dtype=int)\n",
    "                    for stick in subset:\n",
    "                        subset_action[stick - 1] = 1\n",
    "                    if np.all(subset_action <= self.state):\n",
    "                        valid.append(subset_action)\n",
    "        return valid\n",
    "\n",
    "def generate_all_combinations():\n",
    "    all_combinations = {}\n",
    "    action_id = 0\n",
    "\n",
    "    for dice_roll in range(2, 13):\n",
    "        for num_sticks in range(1, min(dice_roll + 1, 13)):\n",
    "            for combination in itertools.combinations(range(1, 13), num_sticks):\n",
    "                if sum(combination) == dice_roll:\n",
    "                    all_combinations[action_id] = combination\n",
    "                    action_id += 1\n",
    "\n",
    "    return all_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "check_env(StickGameEnv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
